{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "testBackprop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.4 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8cd-9aorMJL"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import skimage.io as io\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.morphology import closing, square\n",
        "from skimage.color import label2rgb\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import os\n",
        "import glob\n",
        "import blur"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lOYFuQZrMJR"
      },
      "source": [
        "# From:\n",
        "# https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
        "    try:\n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            gpus[0],\n",
        "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Virtual devices must be set before GPUs have been initialized\n",
        "        print(e)\n",
        "\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = [ 224, 224 ]\n",
        "kVal = 5    # Top 5\n",
        "\n",
        "# IMG_DIMS is [ None, IMG_SIZE, 3 ]\n",
        "IMG_DIMS = [ None ]\n",
        "IMG_DIMS.extend( IMG_SIZE )\n",
        "IMG_DIMS.extend( [3] )\n",
        "\n",
        "# Location of TFRecords\n",
        "recPath = 'records'\n",
        "recName = 'ImageNet'\n",
        "\n",
        "\n",
        "# Display some plots\n",
        "def testLoad( data, info ):\n",
        "\n",
        "    plt.figure( figsize=(10,10) )\n",
        "    i=0\n",
        "    for image, label in data:\n",
        "\n",
        "        if i == 25:\n",
        "            break\n",
        "        plt.subplot( 5, 5, i+1 )\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid( False )\n",
        "        plt.imshow( image )\n",
        "        label = info.features[\"label\"].int2str(label)\n",
        "        plt.xlabel( label )\n",
        "        i += 1\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Read TFRecord file from:\n",
        "# https://stackoverflow.com/questions/47861084/how-to-store-numpy-arrays-as-tfrecord\n",
        "def _parse_tfr_element(element):\n",
        "\n",
        "    parse_dic = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), # Note that it is tf.string, not tf.float32\n",
        "            'label': tf.io.FixedLenFeature([], tf.string),\n",
        "            'bbox': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    example_message = tf.io.parse_single_example(element, parse_dic)\n",
        "\n",
        "    b_image = example_message['image'] # get byte string\n",
        "    b_bbox = example_message['bbox']\n",
        "    b_label = example_message['label']\n",
        "    \n",
        "    img = tf.io.parse_tensor(b_image, out_type=tf.uint8) # restore 2D array from byte string\n",
        "    bbox = tf.io.parse_tensor(b_bbox, out_type=tf.int32)\n",
        "    label = tf.io.parse_tensor(b_label, out_type=tf.string)\n",
        "    label = int(label)\n",
        "\n",
        "    return img, label, bbox\n",
        "\n",
        "\n",
        "def normalize_img( image, label, bbox ):\n",
        "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "    return tf.cast(image, tf.float32) / 255, label, bbox\n",
        "\n",
        "\n",
        "# Python function to manipulate dataset\n",
        "def map_func( image, label, bbox ):\n",
        "    \"\"\" Scales images to IMG_SIZE.\n",
        "        Removes bounding box element of dataset.\"\"\"\n",
        "\n",
        "    # Deal with grayscale images\n",
        "    if len( tf.shape(image) ) == 2:\n",
        "        image = np.expand_dims( image, axis=-1 )\n",
        "        image = tf.concat( [image, image, image], axis=-1 )\n",
        "\n",
        "    image = tf.image.resize( image, IMG_SIZE )\n",
        "\n",
        "    image = blur.applyBlur( image, IMG_SIZE[0]//2, IMG_SIZE[1]//2, 70 )\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# Function to define shape of tfds\n",
        "def ensureShape( image, label ):\n",
        "\n",
        "    # dims -> [ IMG_SIZE, 3 ]\n",
        "    dims = []\n",
        "    dims.extend( IMG_SIZE )\n",
        "    dims.extend( [3] )\n",
        "\n",
        "    image = tf.ensure_shape( image, dims )\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def calcAcc( probs, truth, k ):\n",
        "\n",
        "    numEx = tf.shape( probs )[0]\n",
        "\n",
        "    correctBools = tf.math.in_top_k( truth[ np.arange( 0,numEx ) ], probs, 5 )\n",
        "    numCorrect = tf.math.reduce_sum( tf.cast( correctBools, tf.float32 ) )\n",
        "    print( numCorrect )\n",
        "    print( numCorrect / tf.cast( numEx, tf.float32 ) )\n",
        "\n",
        "    return\n",
        "    \n",
        "\n",
        "def sortRecs( rec ):\n",
        "\n",
        "    fileName, _ = rec.split( '.' )\n",
        "    _, num = fileName.split( '-' )\n",
        "    return int(num)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # Load data\n",
        "    # Iterate through all images of a specific extension in the specified directory\n",
        "    fileName = []\n",
        "    imgPath = os.path.join( recPath, '*.tfrecords' )\n",
        "\n",
        "    for filepath in glob.iglob( imgPath ):\n",
        "        fileName.append( filepath )\n",
        "\n",
        "    # Sort list of tfrecords in numerical ascending order b/c ground truth labels are in that order\n",
        "    fileName.sort( key=sortRecs )  \n",
        "    print( fileName )\n",
        "\n",
        "    tfr_dataset = tf.data.TFRecordDataset(fileName) \n",
        "    dataset = tfr_dataset.map(_parse_tfr_element)\n",
        "\n",
        "    print(\"\\n\\n\\n\\n\")\n",
        "    print( dataset.element_spec )\n",
        "\n",
        "    # Map dataset\n",
        "    ds = dataset.map(\n",
        "        normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    print( ds.element_spec )\n",
        "\n",
        "    # Map using tf.py_function\n",
        "    dsFirst = ds.map( lambda image, label, bbox: tf.py_function(func=map_func,\n",
        "          inp=[image, label, bbox], Tout=[tf.float32, tf.int32]), \n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE )\n",
        "\n",
        "    # Set (previously known) shapes of images\n",
        "    dsFirst = dsFirst.map( \n",
        "        ensureShape, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    print( dsFirst.element_spec )\n",
        "\n",
        "    # for img, label in ds.take(3):\n",
        "        \n",
        "    #     fig, ax = plt.subplots()\n",
        "    #     print( tf.shape( img ) )\n",
        "    #     print( label )\n",
        "    #     img = blur.applyBlur( img, 60, 60, 40 )\n",
        "    #     ax.imshow( img )\n",
        "    #     plt.show()\n",
        "\n",
        "    # Load mapped ground truth labels from a file\n",
        "    with open('truthMapped.pkl', 'rb') as f:\n",
        "        data = f.read() \n",
        "        mappedTruthDict = pickle.loads(data)  \n",
        "    \n",
        "    # Use mappings to get the correct labels\n",
        "    mappedTruthDict = { k:v[0] for (k,v) in mappedTruthDict.items() }\n",
        "    truth = np.array( list( mappedTruthDict.values() ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBRuL2VVrMJT"
      },
      "source": [
        "# Load pre-trained model\n",
        "# Do not use softmax b/c want the raw scores\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v1/classification/4\"),\n",
        "])\n",
        "model.build( IMG_DIMS )  # Batch input shape\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzfydzNJ95IA"
      },
      "source": [
        "dictLabels = {}\r\n",
        "i=0\r\n",
        "\r\n",
        "# Load labels used by the imported GoogLeNet from TensorFlow\r\n",
        "with open( \"ImageNetLabels.txt\" ) as f: \r\n",
        "\r\n",
        "    for line in f:\r\n",
        "\r\n",
        "        dictLabels[i] = line.rstrip()\r\n",
        "        i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbCpW3WDrMJU"
      },
      "source": [
        "dataDir = 'images'\n",
        "fileName = 'ILSVRC2012_val_00000084.JPEG'\n",
        "I = io.imread( '%s'%(fileName) )\n",
        "plt.imshow(I)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0EoUoCkrMJU"
      },
      "source": [
        "topLabel = 0\n",
        "\n",
        "img = I\n",
        "img = tf.image.resize( img, IMG_SIZE )\n",
        "img = img / 255\n",
        "\n",
        "# Save Original\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plt.imshow( img )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "fig.savefig(\"Original.pdf\", bbox_inches='tight')\n",
        "\n",
        "img = blur.applyBlur( img, 112, 112, 70 )\n",
        "img = tf.reshape( img, [1, 224, 224, 3] )\n",
        "image = tf.Variable( img )\n",
        "\n",
        "# Save Blurred\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.add_patch( patches.Circle( (112, 112), 70, fill=False, color='r' ) )\n",
        "plt.imshow( img[0] )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "fig.savefig(\"Blurred.pdf\", bbox_inches='tight')\n",
        "\n",
        "# Loss function\n",
        "bce = tf.keras.losses.BinaryCrossentropy( from_logits=True )\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "\n",
        "    # Watch the input image to compute saliency map later\n",
        "    tape.watch( image )\n",
        "\n",
        "    # Forward-pass to get initial predictions\n",
        "    logits = model( image )\n",
        "\n",
        "    # Get top-k predictions\n",
        "    _, preds = tf.math.top_k(logits, k=kVal) # Throw out the logits for each top prediction (included in logits variable)\n",
        "    print( preds )\n",
        "    true = tf.one_hot( preds[0], len( logits[0] )  )  # One-hot encode the predictions to the same size as logits\n",
        "    print( true )\n",
        "    loss = bce( logits[0], true[topLabel] )\n",
        "    print( loss )\n",
        "\n",
        "grads = abs( tape.gradient( loss, image ) )\n",
        "grads = tf.reduce_max( grads[0], axis=-1 )\n",
        "\n",
        "# Save figure\n",
        "f = plt.figure(figsize=(10, 6))\n",
        "plt.imshow( grads, cmap=\"gray\" )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "f.savefig(\"BeforeThresholding.pdf\", bbox_inches='tight')\n",
        "\n",
        "# Apply initial thresholding\n",
        "thres = tfp.stats.percentile( grads, q=80 )\n",
        "grads = tf.keras.activations.relu( grads, threshold=thres )\n",
        "\n",
        "# Save figure\n",
        "f = plt.figure(figsize=(10, 6))\n",
        "plt.imshow( grads, cmap=\"gray\" )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "f.savefig(\"AfterThresholding.pdf\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR3oAyvE-BE-"
      },
      "source": [
        "# Should be N-1\r\n",
        "N = 84\r\n",
        "tfID = truth[N-1]\r\n",
        "print(tfID)\r\n",
        "print(dictLabels[tfID])\r\n",
        "predLabels = [ dictLabels[i] for i in preds[0].numpy() ]\r\n",
        "print( predLabels )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n85KtO2krMJV"
      },
      "source": [
        "image = grads.numpy()\n",
        "\n",
        "# apply threshold\n",
        "thres = threshold_otsu(image)\n",
        "bw = closing(image > thres, square(3))\n",
        "\n",
        "# label image regions\n",
        "label_image = label(bw)\n",
        "# to make the background transparent, pass the value of `bg_label`,\n",
        "# and leave `bg_color` as `None` and `kind` as `overlay`\n",
        "image_label_overlay = label2rgb(label_image, image=image, bg_label=0)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.imshow(image_label_overlay)\n",
        "\n",
        "for region in regionprops(label_image):\n",
        "    # take regions with large enough areas\n",
        "    if region.area >= 100:\n",
        "        # draw rectangle around segmented coins\n",
        "        minr, minc, maxr, maxc = region.bbox\n",
        "        rect = patches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
        "                                  fill=False, edgecolor='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig(\"SaliencyMap.pdf\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEhnJvUsrMJV"
      },
      "source": [
        "curMaxArea = 0\n",
        "\n",
        "# Get max region\n",
        "for region in regionprops(label_image):\n",
        "    \n",
        "    if region.area >= curMaxArea:\n",
        "\n",
        "        curMaxArea = region.area\n",
        "        maxRegion = region"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLxRD_krMJW"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.imshow( grads, cmap=\"gray\" )\n",
        "\n",
        "minr, minc, maxr, maxc = maxRegion.bbox\n",
        "rect = patches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
        "                            fill=False, edgecolor='red', linewidth=2)\n",
        "ax.add_patch(rect)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.imshow( img[0] )\n",
        "ax.add_patch( patches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
        "                            fill=False, edgecolor='red', linewidth=2) )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVUmQGi7rMJW"
      },
      "source": [
        "# Second pass\n",
        "alpha = 0.5\n",
        "height = maxc - minc\n",
        "width = maxr - minr\n",
        "f_new = np.floor( alpha * np.max( [height, width] ) )\n",
        "f_new = np.max( [30, f_new] )\n",
        "centerX = minc + height/2\n",
        "centerY = minr + width/2\n",
        "print( f_new )\n",
        "imgSec = I\n",
        "imgSec = tf.image.resize( imgSec, IMG_SIZE )\n",
        "imgSec = imgSec / 255\n",
        "imgSec = blur.applyBlur( imgSec, centerX, centerY, f_new )\n",
        "\n",
        "# Show image\n",
        "fig, ax = plt.subplots()\n",
        "plt.imshow( imgSec )\n",
        "ax.add_patch( patches.Circle( (centerX, centerY), f_new, fill=False, color='r' ) )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "imgSec = tf.reshape( imgSec, [1, 224, 224, 3] )\n",
        "fig.savefig(\"Overlaid\" + str(topLabel+1) + \".pdf\", bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT3AWnzNrMJW"
      },
      "source": [
        "logits = model.predict( imgSec )\n",
        "probs = tf.nn.softmax( logits )\n",
        "probs, preds = tf.math.top_k(probs, k=kVal)\n",
        "print( preds )\n",
        "\n",
        "predLabels = [ dictLabels[i] for i in preds[0].numpy() ]\n",
        "print( probs )\n",
        "print( predLabels )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDudSQCNrMJW"
      },
      "source": [
        "dataDir = 'images'\n",
        "fileName = 'ILSVRC2012_val_00000084.JPEG'\n",
        "I = io.imread( '%s'%(fileName) )\n",
        "plt.imshow(I)\n",
        "plt.show()\n",
        "\n",
        "img = I\n",
        "img = tf.image.resize( img, IMG_SIZE )\n",
        "img = img / 255\n",
        "img = blur.applyBlur( img, 112, 112, 70 )\n",
        "img = tf.reshape( img, [1, 224, 224, 3] )\n",
        "imageVar = tf.Variable( img )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak6c7A5YrMJX"
      },
      "source": [
        "topK = 5\n",
        "topKOri = np.zeros( [1,topK] )\n",
        "topKSq = np.zeros( [topK,topK] )\n",
        "confs = np.zeros( [topK,topK] )\n",
        "\n",
        "# Loss function\n",
        "bce = tf.keras.losses.BinaryCrossentropy( from_logits=True )\n",
        "\n",
        "for topLabel in range(topK):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        # Watch the input image to compute saliency map later\n",
        "        tape.watch( imageVar )\n",
        "\n",
        "        # Forward-pass to get initial predictions\n",
        "        probs = model( imageVar )\n",
        "\n",
        "        # Get top-k predictions\n",
        "        logits, preds = tf.math.top_k(probs, k=kVal) # Throw out the probs for each top prediction (included in probs variable)\n",
        "        topKOri = preds\n",
        "        dictOri = dict( zip( preds[0].numpy(), tf.nn.softmax( logits[0] ).numpy() ) )\n",
        "\n",
        "        true = tf.one_hot( preds[0], len( probs[0] )  )  # One-hot encode the predictions to the same size as probs\n",
        "\n",
        "        loss = bce( probs[0], true[topLabel] )\n",
        "\n",
        "\n",
        "    grads = abs( tape.gradient( loss, imageVar ) )\n",
        "    grads = tf.reduce_max( grads[0], axis=-1 )\n",
        "\n",
        "    thres = tfp.stats.percentile( grads, q=80 )\n",
        "    grads = tf.keras.activations.relu( grads, threshold=thres )\n",
        "\n",
        "    image = grads.numpy()\n",
        "\n",
        "    # apply threshold\n",
        "    thres = threshold_otsu(image)\n",
        "    bw = closing(image > thres, square(3))\n",
        "\n",
        "    # label image regions\n",
        "    label_image = label(bw)\n",
        "\n",
        "    curMaxArea = 0\n",
        "\n",
        "    # Get max region\n",
        "    for region in regionprops(label_image):\n",
        "        \n",
        "        if region.area >= curMaxArea:\n",
        "\n",
        "            curMaxArea = region.area\n",
        "            maxRegion = region\n",
        "\n",
        "    minr, minc, maxr, maxc = maxRegion.bbox\n",
        "\n",
        "    # Second pass\n",
        "    height = maxc - minc\n",
        "    width = maxr - minr\n",
        "    f_new = np.floor( np.max( [height, width] ) / 2 )\n",
        "    f_new = np.max( [30, f_new] )   # Minimum foveal size\n",
        "    centerX = minc + height/2\n",
        "    centerY = minr + width/2\n",
        "    print( f_new )\n",
        "    imgSec = I\n",
        "    imgSec = tf.image.resize( imgSec, IMG_SIZE )\n",
        "    imgSec = imgSec / 255\n",
        "    imgSec = blur.applyBlur( imgSec, centerX, centerY, f_new )\n",
        "\n",
        "    # Show image\n",
        "    fig, ax = plt.subplots()\n",
        "    plt.imshow( imgSec )\n",
        "    ax.add_patch( patches.Circle( (centerX, centerY), f_new, fill=False, color='r' ) )\n",
        "    plt.show()\n",
        "    imgSec = tf.reshape( imgSec, [1, 224, 224, 3] )\n",
        "\n",
        "    logits = model.predict( imgSec )\n",
        "    conf, preds = tf.math.top_k(logits, k=kVal)\n",
        "    confs[ topLabel ] = conf\n",
        "    topKSq[ topLabel ] = preds\n",
        "\n",
        "    print( \"\\n\\n\\n\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iyMRKEOrMJX"
      },
      "source": [
        "# Map top-k into dicts\n",
        "dicts = []\n",
        "for i in range( topK ):\n",
        "    dicts.append( dict( zip( topKSq[i], tf.nn.softmax( confs[i] ).numpy() ) ) )\n",
        "\n",
        "# Get the highest confidences for each unique label\n",
        "dictTopK = defaultdict(int)\n",
        "dictTopK.update( dictOri )\n",
        "for i in range(topK):\n",
        "    dictTopK.update( (k,v) for k,v in dicts[i].items() if dictTopK[k] < v )\n",
        "\n",
        "# Sort the dict in descending order\n",
        "# Get topK labels\n",
        "tupleTopK = sorted(dictTopK.items(), key=lambda x: x[1], reverse=True)[:topK]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sX5CjgCrMJX"
      },
      "source": [
        "# Get labels into a list\n",
        "newTopK = [ int(x[0]) for x in tupleTopK ]\n",
        "print( \"Original:\", dictOri )\n",
        "print( \"New:\", dict(dictTopK) )\n",
        "print( \"Final Predictions:\", newTopK )\n",
        "print( \"Original:\", topKOri.numpy() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lyCTmFmaFl1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}